Arborescence


rag-fake-news/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ articles.csv
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ chunks.csv
â”‚   â””â”€â”€ embeddings/
â”‚       â””â”€â”€ chromadb/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clean_text.py
â”‚   â”‚   â”œâ”€â”€ chunk_text.py
â”‚   â”‚   â””â”€â”€ tests_preprocessing.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â””â”€â”€ chromadb_manager.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ generator.py
â”‚   â”‚   â””â”€â”€ prompt_builder.py
â”‚   â”œâ”€â”€ interface/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cli.py
â”‚   â”‚   â””â”€â”€ streamlit_app.py
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ evaluate.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â””â”€â”€ test_generation.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py



# ğŸ§  RAG Fake News Detector

## ğŸ¯ Objectif
Ce projet implÃ©mente un **systÃ¨me de dÃ©tection de fake news** basÃ© sur une approche **Retrieval-Augmented Generation (RAG)**.  
Le but est de vÃ©rifier la vÃ©racitÃ© dâ€™un texte en le comparant Ã  des articles labellisÃ©s (`TRUE` ou `FAKE`) stockÃ©s dans une base vectorielle **ChromaDB**, et dâ€™obtenir un verdict justifiÃ© Ã  lâ€™aide dâ€™un modÃ¨le de langage exÃ©cutÃ© localement avec **Ollama**.

---

## âš™ï¸ Architecture gÃ©nÃ©rale

1. **PrÃ©traitement des articles**
   - Nettoyage, tokenisation et dÃ©coupage des textes en *chunks* homogÃ¨nes.
   - Association de mÃ©tadonnÃ©es (titre, label, source, etc.).

2. **Vectorisation et stockage**
   - Chaque chunk est vectorisÃ© via un modÃ¨le dâ€™embedding (`o4-mini`) exÃ©cutÃ© par Ollama.
   - Les embeddings, textes et mÃ©tadonnÃ©es sont stockÃ©s dans **ChromaDB**.

3. **Recherche sÃ©mantique (retrieval)**
   - Lors de lâ€™analyse dâ€™un nouvel article, le texte est vectorisÃ© et comparÃ© Ã  la base.
   - Les *k* chunks les plus similaires sont rÃ©cupÃ©rÃ©s pour constituer le **contexte**.

4. **GÃ©nÃ©ration du verdict (generation)**
   - Un **prompt** est construit et envoyÃ© Ã  un modÃ¨le LLM local (`o4-mini`).
   - Le modÃ¨le fournit un **verdict** (`TRUE`, `FAKE` ou `UNCERTAIN`) et une **explication courte**. En cas de forte hÃ©sitation le modÃ¨le est forcÃ© Ã  trancher si un label est en forte majoritÃ© (modifiable).

5. **Ã‰valuation**
   - Les rÃ©sultats sont comparÃ©s aux labels rÃ©els pour mesurer la **prÃ©cision**, le **rappel** et la **cohÃ©rence** du systÃ¨me.

---

## ğŸ§© Technologies principales

| Composant | RÃ´le |
|------------|------|
| **Python 3.11+** | Langage principal |
| **o4-mini** | ExÃ©cution locale des modÃ¨les LLM & embeddings |
| **ChromaDB** | Base vectorielle pour le stockage et la recherche sÃ©mantique |
| **Scikit-learn** | Ã‰valuation des performances |
| **NumPy / Pandas** | Traitement des donnÃ©es |

---

## ğŸ“¦ Installation

### 1. Cloner le projet
```bash
git clone https://github.com/https://github.com/samyachd/rag_fake_news/rag_fake_news.git
cd rag_fake_news
